{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87c165-0e9f-478a-a206-9c6cf0568795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a93b6d-b3ae-4f1b-90dc-4f8f78cf8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"penguins_size.csv\")\n",
    "df = df.drop([\"island\",\"culmen_depth_mm\",\"flipper_length_mm\"],axis = 1)\n",
    "df = df[df['species'] == 'Adelie']\n",
    "df = df.drop([\"species\"],axis = 1)\n",
    "df = df.dropna()\n",
    "df['sex'] = df['sex'].replace({'FEMALE': 1, 'MALE': -1})\n",
    "df['sex'] = df['sex'].astype(float)\n",
    "X = df.iloc[:, :-1].values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = df.iloc[:, -1].values  \n",
    "Y = Y.reshape(-1, 1).astype(float) \n",
    "#Y[Y == 0] = -1 \n",
    "X_and_Y = np.hstack((X, Y))     \n",
    "np.random.seed(1)              \n",
    "np.random.shuffle(X_and_Y)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622669d5-684f-4ceb-a37e-e3a12a2f2661",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f8d9c-41a0-4f79-80cb-1a90a09540ac",
   "metadata": {},
   "source": [
    "# 20 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afeb2ed-e096-4446-87ef-a9a5b59c2979",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.8 * len(X_shuffled))  # 80% for training\n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e1686-30b0-47bb-9791-6932e72a8913",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Sigmoid function: sigmoid(z) = 1/(1 + e^(-z))\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "# Judge function: 1(a != b).\n",
    "def judge(a, b):\n",
    "    \"\"\"\n",
    "    Judge function: 1(a != b).\n",
    "    Return 1 if a != b, otherwise return 0.\n",
    "    \"\"\"\n",
    "    if a != b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def f_logistic(x, W, b):\n",
    "    \"\"\"\n",
    "    Logistic classifier: f(x, W, b)\n",
    "    This function should return -1 or 1.\n",
    "\n",
    "    x should be a 2-dimensional vector, \n",
    "    W should be a 2-dimensional vector,\n",
    "    b should be a scalar.\n",
    "    \"\"\"\n",
    "    if sigmoid(W.T.dot(x)+b) >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error(X, Y, W, b):\n",
    "    e = 0\n",
    "    n = len(X)\n",
    "    for (xi, yi) in zip(X, Y):\n",
    "        # Hint: Use judge() and f_logistic()\n",
    "        predicted_label = f_logistic(xi, W, b)\n",
    "        e+=judge(yi, predicted_label)\n",
    "    \n",
    "    # Hint: remember we want the average error.\n",
    "    e = 1.0*e/n\n",
    "    return e\n",
    "# Gradient of L(W, b) with respect to W and b.\n",
    "def grad_L_W_b(X, Y, W, b):\n",
    "    P = sigmoid(Y*(np.dot(X, W)+b))\n",
    "    delta = np.ones_like(Y)-P\n",
    "    grad_W = -np.dot(X.T,delta*Y)\n",
    "    grad_b = -np.dot(np.ones(delta.shape).T, delta * Y) #dotting ones is the same as summing everything, wow\n",
    "    return grad_W, grad_b\n",
    "# Loss L(W, b).\n",
    "def L_W_b(X, Y, W, b):\n",
    "    P = sigmoid(Y*(np.dot(X, W)+b))\n",
    "    loss = -np.dot(np.ones_like(Y).T, np.log(P))\n",
    "\n",
    "    return loss\n",
    "def logistic_regression(X_train, Y_train):\n",
    "    # Some settings.\n",
    "    losses = []           # Error history.\n",
    "    learning_rate = 0.001 # Learning rate, fixed\n",
    "    iterations    = 10000 # Iteration number, fixed\n",
    "\n",
    "    # Gradient descent algorithm for logistic regression.\n",
    "    # Step 1. Initialize the parameters W, b.\n",
    "    W      = np.zeros(2)  # Weight.\n",
    "    b      = 0.0          # Bias.\n",
    "\n",
    "    # Logistic regression learning algorithm.\n",
    "    for i in range(iterations):\n",
    "        # Step 2. Compute the partial derivatives.\n",
    "        grad_W, grad_b = grad_L_W_b(X_train, Y_train, W, b)\n",
    "        # Step 3. Update the parameters.\n",
    "        W = W-learning_rate*grad_W\n",
    "        b = b-learning_rate*grad_b\n",
    "        \n",
    "        # Track the training losses.\n",
    "        loss = L_W_b(X_train, Y_train, W, b)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return W, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24903db0-2008-45f1-851c-5cfc51bd6f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6022e1a-cc46-427a-8025-2e68023fc6ab",
   "metadata": {},
   "source": [
    "# 50 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32129068-a611-4172-83c8-584cd822f525",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.5 * len(X_shuffled))  # 80% for training\n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c807de-05eb-40b7-868e-521f0f9f5d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c920df-d131-45a7-aab5-58db034fe305",
   "metadata": {},
   "source": [
    "# 80 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e280c-060a-474b-803a-99373353de73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.8 * len(X_shuffled))  # 80% for training\n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf140b-cdcb-4372-ace8-d3ad00e21b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4b473-cfba-4791-ac92-12eab7ea8212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea9a7e-fc67-4516-9654-736ba098c905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8816521-29a2-4adf-84eb-a87657a3da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "from matplotlib.colors import ListedColormap\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d54c834-b979-4fbc-96e4-4c1e52fdbe94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1     2     3     4      5     6     7     8     9      10    11  \\\n",
      "0    1.0  14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29   5.64  1.04   \n",
      "1    1.0  13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28   4.38  1.05   \n",
      "2    1.0  13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81   5.68  1.03   \n",
      "3    1.0  14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18   7.80  0.86   \n",
      "4    1.0  13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82   4.32  1.04   \n",
      "..   ...    ...   ...   ...   ...    ...   ...   ...   ...   ...    ...   ...   \n",
      "173  3.0  13.71  5.65  2.45  20.5   95.0  1.68  0.61  0.52  1.06   7.70  0.64   \n",
      "174  3.0  13.40  3.91  2.48  23.0  102.0  1.80  0.75  0.43  1.41   7.30  0.70   \n",
      "175  3.0  13.27  4.28  2.26  20.0  120.0  1.59  0.69  0.43  1.35  10.20  0.59   \n",
      "176  3.0  13.17  2.59  2.37  20.0  120.0  1.65  0.68  0.53  1.46   9.30  0.60   \n",
      "177  3.0  14.13  4.10  2.74  24.5   96.0  2.05  0.76  0.56  1.35   9.20  0.61   \n",
      "\n",
      "       12      13  \n",
      "0    3.92  1065.0  \n",
      "1    3.40  1050.0  \n",
      "2    3.17  1185.0  \n",
      "3    3.45  1480.0  \n",
      "4    2.93   735.0  \n",
      "..    ...     ...  \n",
      "173  1.74   740.0  \n",
      "174  1.56   750.0  \n",
      "175  1.56   835.0  \n",
      "176  1.62   840.0  \n",
      "177  1.60   560.0  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wine.data', header=None, delimiter=',', dtype=float)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d03266f-2a36-43be-9912-333a1d627827",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop([2,3,4,5,6,8,9,10,11,12,13], axis=1)\n",
    "df = df[df[0] != 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02c5231-016b-463b-9732-3150c5a8344a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.07</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.43</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.79</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.37</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.04</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     7\n",
       "0    1.0  14.23  3.06\n",
       "1    1.0  13.20  2.76\n",
       "2    1.0  13.16  3.24\n",
       "3    1.0  14.37  3.49\n",
       "4    1.0  13.24  2.69\n",
       "..   ...    ...   ...\n",
       "125 -1.0  12.07  2.65\n",
       "126 -1.0  12.43  3.15\n",
       "127 -1.0  11.79  2.24\n",
       "128 -1.0  12.37  2.45\n",
       "129 -1.0  12.04  1.75\n",
       "\n",
       "[130 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0] = df[0].replace({1.0: 1, 2.0: -1})\n",
    "df[0] = df[0].astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69098655-2c82-4bd9-adc4-803456b2885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 2)\n",
      "(130, 1)\n",
      "[-0.81784764 -0.61230964 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 1:3].values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X) \n",
    "Y = df.iloc[:, 0].values    \n",
    "Y = Y.reshape(-1, 1).astype(float)  \n",
    "X_and_Y = np.hstack((X, Y))     \n",
    "np.random.seed(1)              \n",
    "np.random.shuffle(X_and_Y)     \n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_and_Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcc1b2-9a7f-4be3-903f-add6518670cf",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5992505-f81c-4a5f-b471-f532f73045c5",
   "metadata": {},
   "source": [
    "# 20 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dd7a1a2-52b9-4cba-9988-41bb9714eb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 2)\n",
      "(26,)\n",
      "(104, 2)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.2 * len(X_shuffled)) \n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffd4fae-6efa-4c20-a15e-011a9cdff13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function: sigmoid(z) = 1/(1 + e^(-z))\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "# Judge function: 1(a != b).\n",
    "def judge(a, b):\n",
    "    \"\"\"\n",
    "    Judge function: 1(a != b).\n",
    "    Return 1 if a != b, otherwise return 0.\n",
    "    \"\"\"\n",
    "    if a != b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def f_logistic(x, W, b):\n",
    "    \"\"\"\n",
    "    Logistic classifier: f(x, W, b)\n",
    "    This function should return -1 or 1.\n",
    "\n",
    "    x should be a 2-dimensional vector, \n",
    "    W should be a 2-dimensional vector,\n",
    "    b should be a scalar.\n",
    "    \"\"\"\n",
    "    if sigmoid(W.T.dot(x)+b) >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Calculate error given feature vectors X and labels Y.\n",
    "def calc_error(X, Y, W, b):\n",
    "    e = 0\n",
    "    n = len(X)\n",
    "    for (xi, yi) in zip(X, Y):\n",
    "        # Hint: Use judge() and f_logistic()\n",
    "        predicted_label = f_logistic(xi, W, b)\n",
    "        e+=judge(yi, predicted_label)\n",
    "    \n",
    "    # Hint: remember we want the average error.\n",
    "    e = 1.0*e/n\n",
    "    return e\n",
    "# Gradient of L(W, b) with respect to W and b.\n",
    "def grad_L_W_b(X, Y, W, b):\n",
    "    P = sigmoid(Y*(np.dot(X, W)+b))\n",
    "    delta = np.ones_like(Y)-P\n",
    "    grad_W = -np.dot(X.T,delta*Y)\n",
    "    grad_b = -np.dot(np.ones(delta.shape).T, delta * Y) #dotting ones is the same as summing everything, wow\n",
    "    return grad_W, grad_b\n",
    "# Loss L(W, b).\n",
    "def L_W_b(X, Y, W, b):\n",
    "    P = sigmoid(Y*(np.dot(X, W)+b))\n",
    "    loss = -np.dot(np.ones_like(Y).T, np.log(P))\n",
    "\n",
    "    return loss\n",
    "def logistic_regression(X_train, Y_train):\n",
    "    # Some settings.\n",
    "    losses = []           # Error history.\n",
    "    learning_rate = 0.001 # Learning rate, fixed\n",
    "    iterations    = 10000 # Iteration number, fixed\n",
    "\n",
    "    # Gradient descent algorithm for logistic regression.\n",
    "    # Step 1. Initialize the parameters W, b.\n",
    "    W      = np.zeros(2)  # Weight.\n",
    "    b      = 0.0          # Bias.\n",
    "\n",
    "    # Logistic regression learning algorithm.\n",
    "    for i in range(iterations):\n",
    "        # Step 2. Compute the partial derivatives.\n",
    "        grad_W, grad_b = grad_L_W_b(X_train, Y_train, W, b)\n",
    "        # Step 3. Update the parameters.\n",
    "        W = W-learning_rate*grad_W\n",
    "        b = b-learning_rate*grad_b\n",
    "        \n",
    "        # Track the training losses.\n",
    "        loss = L_W_b(X_train, Y_train, W, b)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return W, b, losses\n",
    "#W,b = logistic_regression(X_train, Y_train)\n",
    "def cross_validate_logistic_regression(X, Y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    validation_errors = []  # To store validation errors for each fold\n",
    "    models = []  # To store W, b, and losses for each fold\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "        # Train the model on the training data\n",
    "        W, b, losses = logistic_regression(X_train, Y_train)\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        error = calc_error(X_val, Y_val, W, b)\n",
    "        validation_errors.append(error)\n",
    "        \n",
    "        # Store the model for this fold\n",
    "        models.append((W, b, losses))\n",
    "    \n",
    "    # Average validation error across folds\n",
    "    avg_validation_error = np.mean(validation_errors)\n",
    "    return avg_validation_error, models, validation_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0953bc9f-536b-43c8-86b9-51fc0fd3fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001, Average Cross-Validation Score: 0.5199999999999999\n",
      "C: 0.01, Average Cross-Validation Score: 0.7200000000000001\n",
      "C: 0.1, Average Cross-Validation Score: 0.96\n",
      "C: 1, Average Cross-Validation Score: 0.9199999999999999\n",
      "C: 10, Average Cross-Validation Score: 0.9199999999999999\n",
      "C: 100, Average Cross-Validation Score: 0.9199999999999999\n",
      "Best C: 0.1 with score: 0.96\n",
      "Training accuracy: 0.9230769230769231\n",
      "Training error: 0.07692307692307687\n",
      "Test accuracy: 0.9230769230769231\n",
      "Test error: 0.07692307692307687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf22d3-b374-4eb6-8521-5863aee3ef8f",
   "metadata": {},
   "source": [
    "# 50 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21cb7871-903b-43d7-87ec-d6ee465fa96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 2)\n",
      "(65,)\n",
      "(65, 2)\n",
      "(65,)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.5 * len(X_shuffled))\n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8d3ec82-6934-4f39-a9c1-e05448b16607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001, Average Cross-Validation Score: 0.5692307692307692\n",
      "C: 0.01, Average Cross-Validation Score: 0.6923076923076923\n",
      "C: 0.1, Average Cross-Validation Score: 0.876923076923077\n",
      "C: 1, Average Cross-Validation Score: 0.8923076923076924\n",
      "C: 10, Average Cross-Validation Score: 0.876923076923077\n",
      "C: 100, Average Cross-Validation Score: 0.876923076923077\n",
      "Best C: 1 with score: 0.8923076923076924\n",
      "Training accuracy: 0.9230769230769231\n",
      "Training error: 0.07692307692307687\n",
      "Test accuracy: 0.9384615384615385\n",
      "Test error: 0.06153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e9ce3-94ea-4ca9-90c1-db342dc969c0",
   "metadata": {},
   "source": [
    "# 80 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb51af21-626d-42fc-a83a-efed8672572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 2)\n",
      "(104,)\n",
      "(26, 2)\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "# Divide the data points into training set and test set.\n",
    "X_shuffled = X_and_Y[:,:2]\n",
    "Y_shuffled = X_and_Y[:,2]\n",
    "\n",
    "split_index = int(0.8 * len(X_shuffled))\n",
    "\n",
    "X_train = X_shuffled[:split_index]\n",
    "Y_train = Y_shuffled[:split_index]\n",
    "X_test = X_shuffled[split_index:]\n",
    "Y_test = Y_shuffled[split_index:]   \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51235b46-5425-4e1a-a42f-da0c031edf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001, Average Cross-Validation Score: 0.5671428571428571\n",
      "C: 0.01, Average Cross-Validation Score: 0.8571428571428571\n",
      "C: 0.1, Average Cross-Validation Score: 0.9047619047619048\n",
      "C: 1, Average Cross-Validation Score: 0.9333333333333333\n",
      "C: 10, Average Cross-Validation Score: 0.9238095238095239\n",
      "C: 100, Average Cross-Validation Score: 0.9238095238095239\n",
      "Best C: 1 with score: 0.9333333333333333\n",
      "Training accuracy: 0.9423076923076923\n",
      "Training error: 0.05769230769230771\n",
      "Test accuracy: 0.8846153846153846\n",
      "Test error: 0.11538461538461542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "best_C = None\n",
    "best_score = 0\n",
    "#Cross validation\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='lbfgs')\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=5)  # 5-fold cross-validation\n",
    "    avg_score = scores.mean()\n",
    "    \n",
    "    print(f\"C: {C}, Average Cross-Validation Score: {avg_score}\")\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C: {best_C} with score: {best_score}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "final_model = LogisticRegression(C=best_C, solver='lbfgs')\n",
    "final_model.fit(X_train, Y_train)\n",
    "Y_train_pred = final_model.predict(X_train)\n",
    "training_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "training_error = 1 - training_accuracy\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training error: {training_error}\")\n",
    "Y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Test error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a92e2-98a3-4cf1-97ea-85d361a1b668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
